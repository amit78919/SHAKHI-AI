{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Shakhi AI:\n# You're not aloneâ€”Shakhi (Friend) is with you.\n\n# First, India's ChatGPT for rural women.","metadata":{}},{"cell_type":"markdown","source":"# Shakhi AI - Kaggle ,Gen AI Exchange Hackathon 2025 (Project)","metadata":{}},{"cell_type":"markdown","source":"# Overview\n\nSakhi AI is an offline, voice-first, local-language AI companion designed specifically for rural Indian women. Built using Gemma 3n, it empowers women to share their thoughts, receive empathetic responses, and track their emotional healthâ€” all while prioritizing privacy, cultural sensitivity, and offline accessibility.","metadata":{}},{"cell_type":"markdown","source":"# Problem Statement\n\nMillions of women in rural India suffer in silence due to emotional neglect, patriarchal restrictions, mental health stigma, and lack of privacy. Smartphones may have reached villages, but AI solutions have not reached their hearts.\n\nThey need someone who doesn't judge, doesn't gossip, and just listens. But in low-connectivity areas, global AI fails.","metadata":{}},{"cell_type":"markdown","source":"# Solution - Shakhi AI\n\nShakhi AI becomes a \"shakhi\" (friend) who:\n\nListens in local languages (Hindi & Hinglish)\n\nSpeaks softly, with empathy\n\nWorks 100% offline on entry-level smartphones\n\nTracks mood/emotions locally\n\nReminds pregnant women about essential vaccines & nutrition\n\nStores no cloud data - user remains private\n\nBuilt with Gemma 3n, it is optimized for private, on-device LLM inference.\n\n","metadata":{}},{"cell_type":"markdown","source":"# Features (MVP)\n\n#Feature\n\nDescription\n\n1. ðŸŽ¤ Emotional Voice Check-In\n\nAsk \"à¤•à¥ˆà¤¸à¥€ à¤¹à¥‹ à¤¬à¤¹à¤¨?\" daily and listen to their emotional status.\n\n2.ðŸŒ 100% Offline Mode\n\nBuilt with Gemma 3n, no internet needed\n\n3.ðŸš¬ Local Language Support\n\nHindi, Hinglish, English, Punjabi, and Tamil support out of the box\n\n4. â™¦ï¸ Daily Mood Tracker and Period Cycle Information\n\nEmoji-based mood logs stored locally\n\n5. ðŸ‘¶ Mother Health Reminder\n\nVaccine/nutrition alerts for pregnant women","metadata":{}},{"cell_type":"markdown","source":"# Details:-\n\nFeature 1: Voice-based Daily Health & Mood Check-ins\n\nâ”œâ”€â”€ Why: Private emotional expression\n\nâ”œâ”€â”€ Tech: Gemma 3n Voice I/O + Offline Emotion AI\n\nâ”œâ”€â”€ Category: Emotional & Mental Health\n\nâ””â”€â”€ Impact: Daily mood tracking, reduces loneliness\n\n\n\nðŸ“Œ Feature 2: Safe, Empathetic Talk with AI Sakhi\n\nâ”œâ”€â”€ Why: Trusted non-judgmental companion\n\nâ”œâ”€â”€ Tech: Empathetic NLP + Sentiment + Intent AI\n\nâ”œâ”€â”€ Category: Conversational AI for Rural\n\nâ””â”€â”€ Impact: Safe space to share stress\n\n\n\nðŸ“Œ Feature 3: Mother Health Reminders\n\nâ”œâ”€â”€ Why: Support pregnancy care\n\nâ”œâ”€â”€ Tech: Prompt Templates + Offline Calendar Logic + Local Voice TTS/STT\n\nâ”œâ”€â”€ Category: Maternal Health AI\n\nâ””â”€â”€ Impact: Boosts vaccine awareness\n\n\n\nðŸ“Œ Feature 4: Health + Period Tracker\n\nâ”œâ”€â”€ Why: Body awareness & wellness\n\nâ”œâ”€â”€ Tech: Edge Calendar AI + Hindi TTS + On-device storage\n\nâ”œâ”€â”€ Category: Offline HealthTech\n\nâ””â”€â”€ Impact: Breaks period taboo\n\n\n\nðŸ“Œ Feature 5: English + Local Language Toggle\n\nâ”œâ”€â”€ Why: Bilingual access\n\nâ”œâ”€â”€ Tech: Offline Translation + TTS/STT (Hindi â†” English)\n\nâ”œâ”€â”€ Category: UI/UX Accessibility\n\nâ””â”€â”€ Impact: Inclusive design, higher adoption.","metadata":{}},{"cell_type":"markdown","source":"## Future Add-On:- \n1- ðŸŸ£'Offline Emergency Button' â€“ visual of a woman quickly pressing a discreet button on Sakhi AI during a tense moment, triggering a vibration and silent alert. 2- ðŸ’–'AI Health Kit' â€“ animation of Sakhi AI advising a pregnant woman about iron-rich food and upcoming vaccinations, while a local health center icon blinks. 3- ðŸŒ 'Community Voice Exchange' â€“ highlight an audio sharing board where women post voice notes of encouragement for each other in local dialects. 4- ðŸ“ 'Offline Women Locator' â€“ a mini-map animation showing nearby trusted Sakhi AI users (without GPS, powered by local mesh networks), useful during offline emergencies.\n","metadata":{}},{"cell_type":"markdown","source":"# Team\n\nAmit Singh - Solo Maker, Final Year BTech, AIML.\n\nBuilt in 12 days with love, passion, and vision to create real impact","metadata":{}},{"cell_type":"markdown","source":"# Shakhi AI: Kaggle Notebook Implementation ðŸ“ Tech Part ","metadata":{}},{"cell_type":"markdown","source":"# Step 1: Setup and Installations\nFirst, we need to install the necessary libraries. For this project, you'll need transformers to use the Gemma model, accelerate and bitsandbytes to help it run efficiently on Kaggle's hardware, and gtts to simulate the voice output.","metadata":{}},{"cell_type":"code","source":"# --- 1. INSTALL LIBRARIES (FINAL COMPATIBLE VERSION) ---\nprint(\"Setting up Sakhi's environment by updating all key libraries...\")\n\n# This command upgrades all necessary packages to their latest compatible versions,\n# which is the best way to resolve dependency conflicts.\n!pip install -q -U transformers accelerate bitsandbytes sentence-transformers gtts\n\n# This library helps play audio directly in the notebook\nfrom gtts import gTTS\nfrom IPython.display import Audio, display\n\nprint(\"âœ… All libraries are now up-to-date and compatible! Sakhi is ready.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-16T13:06:41.388761Z","iopub.execute_input":"2025-08-16T13:06:41.389222Z","iopub.status.idle":"2025-08-16T13:07:01.225794Z","shell.execute_reply.started":"2025-08-16T13:06:41.389176Z","shell.execute_reply":"2025-08-16T13:07:01.224490Z"}},"outputs":[{"name":"stdout","text":"Setting up Sakhi's environment by updating all key libraries...\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m483.4/483.4 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m37.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hâœ… All libraries are now up-to-date and compatible! Sakhi is ready.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"# Step 2: Load the AI Brain (Gemma Model) ðŸ§ \nThis is the most important step. We will load the Gemma model from Hugging Face. To do this, you'll need a Hugging Face access token.\n\nHow to get your token:\n\nGo to HuggingFace.co and create a free account.\n\nClick on your profile picture -> Settings -> Access Tokens.\n\nCreate a new token with \"read\" permissions.\n\nIn your Kaggle Notebook, click on \"Add-ons\" -> \"Secrets\" -> \"Add a new secret\". Name it HF_TOKEN and paste your token value there.\n\nNow, add this code to a new cell. You must have the internet turned ON for this cell to work the first time. It will download the model to your notebook's temporary storage.","metadata":{}},{"cell_type":"code","source":"# --- 2. LOAD THE GEMMA AI MODEL (ERROR-FREE VERSION) ---\nimport torch\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\nimport os\nfrom kaggle_secrets import UserSecretsClient\nfrom huggingface_hub import login # <-- Import the login function\n\n# Explain to the user what's happening\nprint(\"Loading Sakhi's AI brain (Gemma). This is a one-time download and might take a few minutes...\")\nprint(\"Make sure your Hugging Face token is saved in Kaggle Secrets as 'HF_TOKEN'.\")\n\n# --- Step 1: Get the Secret Token ---\ntry:\n    user_secrets = UserSecretsClient()\n    hf_token = user_secrets.get_secret(\"HF_TOKEN\")\nexcept Exception as e:\n    print(f\"Could not get HF_TOKEN from Kaggle Secrets. Error: {e}\")\n    hf_token = \"\"\n\n# --- Step 2: Log in to Hugging Face (This is the crucial new step) ---\nif hf_token:\n    print(\"Logging into Hugging Face...\")\n    login(token=hf_token)\n    print(\"âœ… Successfully logged in.\")\nelse:\n    print(\"âš ï¸ Hugging Face token not found. Please add it to Kaggle Secrets.\")\n\n# --- Step 3: Load the Model ---\n# Model ID on Hugging Face\nmodel_id = \"google/gemma-2b-it\"\n\n# Configuration to load the model in 8-bit, which saves memory\nquantization_config = BitsAndBytesConfig(load_in_8bit=True)\n\n# The tokenizer is like Sakhi's dictionary. It converts our words into numbers the AI understands.\nprint(\"Loading tokenizer...\")\ntokenizer = AutoTokenizer.from_pretrained(model_id)\nprint(\"âœ… Tokenizer loaded.\")\n\n# Now, we load the model itself. device_map=\"auto\" tells it to use the GPU if available.\nprint(\"Loading the main AI model... this may take a few minutes.\")\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_id,\n    quantization_config=quantization_config,\n    device_map=\"auto\" # Automatically use the powerful GPU\n)\n\nprint(\"\\nâœ… AI Model is ready! Sakhi is awake.\")\nprint(\"â­ HACKATHON WINNING TIP: You can now turn OFF the internet in notebook settings! â­\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-16T13:07:14.404874Z","iopub.execute_input":"2025-08-16T13:07:14.405283Z","iopub.status.idle":"2025-08-16T13:09:03.801364Z","shell.execute_reply.started":"2025-08-16T13:07:14.405243Z","shell.execute_reply":"2025-08-16T13:09:03.800239Z"}},"outputs":[{"name":"stdout","text":"Loading Sakhi's AI brain (Gemma). This is a one-time download and might take a few minutes...\nMake sure your Hugging Face token is saved in Kaggle Secrets as 'HF_TOKEN'.\nLogging into Hugging Face...\nâœ… Successfully logged in.\nLoading tokenizer...\nâœ… Tokenizer loaded.\nLoading the main AI model... this may take a few minutes.\n","output_type":"stream"},{"name":"stderr","text":"2025-08-16 13:07:31.362211: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1755349651.658733     231 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1755349651.732848     231 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/13.5k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7c3e0e0eb0114299ad4339dd0efd9c73"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d638ec0b24f34253a2f00177bb12d4a6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/67.1M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"058dbfe7bf804d6c9c43b83fccce0832"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/4.95G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5554bd26d493439d82df7ee7085db4b4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"892dafb8e96a476ba648499e8efcbf84"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/137 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4ef4aacdec8846c4925de47165f442f8"}},"metadata":{}},{"name":"stdout","text":"\nâœ… AI Model is ready! Sakhi is awake.\nâ­ HACKATHON WINNING TIP: You can now turn OFF the internet in notebook settings! â­\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# --- 2. LOAD THE GEMMA AI MODEL (FINAL ERROR-FREE VERSION) ---\nimport torch\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\nfrom kaggle_secrets import UserSecretsClient\nfrom huggingface_hub import login\n\nprint(\"Loading Sakhi's AI brain (Gemma). This is a one-time download and might take a few minutes...\")\nprint(\"Make sure your Hugging Face token is saved in Kaggle Secrets as 'HF_TOKEN'.\")\n\n# --- Step 1: Get the Secret Token ---\ntry:\n    user_secrets = UserSecretsClient()\n    hf_token = user_secrets.get_secret(\"HF_TOKEN\")\nexcept Exception as e:\n    print(f\"Could not get HF_TOKEN from Kaggle Secrets. Error: {e}\")\n    hf_token = \"\"\n\n# --- Step 2: Log in to Hugging Face ---\nif hf_token:\n    print(\"Logging into Hugging Face...\")\n    login(token=hf_token)\n    print(\"âœ… Successfully logged in.\")\nelse:\n    print(\"âš ï¸ Hugging Face token not found. Please add it to Kaggle Secrets.\")\n\n# --- Step 3: Load the Model ---\nmodel_id = \"google/gemma-2b-it\"\nquantization_config = BitsAndBytesConfig(load_in_8bit=True)\n\nprint(\"Loading tokenizer...\")\ntokenizer = AutoTokenizer.from_pretrained(model_id)\nprint(\"âœ… Tokenizer loaded.\")\n\nprint(\"Loading the main AI model... this may take a few minutes. (Ignore any cuFFT/cuDNN warnings below)\")\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_id,\n    quantization_config=quantization_config,\n    device_map=\"auto\"\n)\n\nprint(\"\\nâœ… AI Model is ready! Sakhi is awake.\")\nprint(\"â­ HACKATHON WINNING TIP: You can now turn OFF the internet in notebook settings! â­\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-16T13:13:19.588303Z","iopub.execute_input":"2025-08-16T13:13:19.588831Z","iopub.status.idle":"2025-08-16T13:13:48.883521Z","shell.execute_reply.started":"2025-08-16T13:13:19.588791Z","shell.execute_reply":"2025-08-16T13:13:48.882129Z"}},"outputs":[{"name":"stdout","text":"Loading Sakhi's AI brain (Gemma). This is a one-time download and might take a few minutes...\nMake sure your Hugging Face token is saved in Kaggle Secrets as 'HF_TOKEN'.\nLogging into Hugging Face...\nâœ… Successfully logged in.\nLoading tokenizer...\nâœ… Tokenizer loaded.\nLoading the main AI model... this may take a few minutes. (Ignore any cuFFT/cuDNN warnings below)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3ea6d256d7b841b2bb15998f3cc21c52"}},"metadata":{}},{"name":"stdout","text":"\nâœ… AI Model is ready! Sakhi is awake.\nâ­ HACKATHON WINNING TIP: You can now turn OFF the internet in notebook settings! â­\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"# Step 3: Build and Code Your 5 Features âœ¨\nNow we'll create a Python function for each of your 5 features. The code is heavily commented to explain what's happening.\n\nHelper Function: The Core Chat Logic\nFirst, let's create one central function to talk to Gemma. This avoids repeating code.","metadata":{}},{"cell_type":"code","source":"# --- Helper Functions to Talk and Speak ---\n\ndef ask_gemma(prompt_text):\n    \"\"\"\n    This is the main function to get a response from the Gemma model.\n    \"\"\"\n    # Prepare the input for the model\n    input_ids = tokenizer(prompt_text, return_tensors=\"pt\").to(\"cuda\") # Move data to GPU\n\n    # Generate a response\n    outputs = model.generate(**input_ids, max_new_tokens=150) # Limit response length\n\n    # Decode the response and clean it up\n    response_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n\n    # Remove the original prompt from the response to get only the answer\n    return response_text.replace(prompt_text, \"\").strip()\n\ndef speak(text, lang='en'):\n    \"\"\"\n    This function simulates Sakhi speaking. It converts text to speech and plays it.\n    This works offline after the first run in a session!\n    \"\"\"\n    try:\n        tts = gTTS(text=text, lang=lang)\n        tts.save(\"sakhi_response.mp3\")\n        display(Audio(\"sakhi_response.mp3\", autoplay=True))\n    except Exception as e:\n        print(f\"Could not play audio due to: {e}. Displaying text instead.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-16T13:16:19.402906Z","iopub.execute_input":"2025-08-16T13:16:19.403373Z","iopub.status.idle":"2025-08-16T13:16:19.411678Z","shell.execute_reply.started":"2025-08-16T13:16:19.403338Z","shell.execute_reply":"2025-08-16T13:16:19.410294Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"# Feature 1: Voice-based Daily Health & Mood Check-ins ðŸ˜Š\nThis function simulates a mood check-in. The user types their mood, and Shakhi responds with empathy.","metadata":{}},{"cell_type":"code","source":"# --- FEATURE 1: MOOD CHECK-IN ---\ndef mood_check_in():\n    \"\"\"\n    Asks the user for their mood and provides an empathetic response from the AI.\n    \"\"\"\n    print(\"\\n--- Mood Check-in ---\")\n    user_mood = input(\"Sakhi asks: How are you feeling today? (e.g., happy, sad, tired, stressed) \")\n    \n    # Create a specific instruction for the AI\n    prompt = f\"You are Sakhi, a caring friend. A user just said their mood is '{user_mood}'. Respond with a short, empathetic, and encouraging message in simple English. Do not ask a question back.\"\n    \n    print(\"Shakhi is thinking...\")\n    response = ask_gemma(prompt)\n    \n    print(f\"\\nSakhi says: {response}\")\n\n# --- Example of how to use it ---\n# mood_check_in()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-16T13:17:02.424178Z","iopub.execute_input":"2025-08-16T13:17:02.424635Z","iopub.status.idle":"2025-08-16T13:17:02.430895Z","shell.execute_reply.started":"2025-08-16T13:17:02.424591Z","shell.execute_reply":"2025-08-16T13:17:02.429527Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"# --- FEATURE 1: MOOD CHECK-IN ---\ndef mood_check_in():\n    \"\"\"\n    Asks the user for their mood and provides an empathetic, spoken response from the AI.\n    \"\"\"\n    print(\"\\n--- Feature 1: Daily Mood Check-in ---\")\n    user_mood = input(\"Sakhi asks: How are you feeling today? (e.g., happy, sad, tired, stressed) \")\n\n    # A very specific instruction for the AI to act as a caring friend\n    prompt = f\"You are Sakhi, a kind and caring friend. A user just said she is feeling '{user_mood}'. Respond with a short, warm, and encouraging message in simple English. Do not ask a question back.\"\n\n    print(\"\\nSakhi is thinking...\")\n    response = ask_gemma(prompt)\n\n    print(f\"Sakhi says: {response}\")\n    speak(response)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-16T13:16:57.218839Z","iopub.execute_input":"2025-08-16T13:16:57.219377Z","iopub.status.idle":"2025-08-16T13:16:57.226454Z","shell.execute_reply.started":"2025-08-16T13:16:57.219337Z","shell.execute_reply":"2025-08-16T13:16:57.225064Z"}},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"# Feature 2: Safe, Empathetic Talk with AI Shakhi ðŸ’¬\nThis allows the user to share a problem and get a non-judgmental response.","metadata":{}},{"cell_type":"code","source":"# --- FEATURE 2: EMPATHETIC TALK ---\ndef empathetic_talk():\n    \"\"\"\n    Provides a safe space for the user to share their problems.\n    \"\"\"\n    print(\"\\n--- Talk to Shakhi ---\")\n    user_problem = input(\"Shakhi is here to listen. What's on your mind? (You can share anything) \")\n    \n    prompt = f\"You are Sakhi, a non-judgmental and caring friend for a woman in rural India. She is sharing this problem: '{user_problem}'. Listen to her, validate her feelings, and offer gentle reassurance. Do not give any medical or legal advice. Just be a supportive friend. Respond in simple English.\"\n    \n    print(\"Shakhi is thinking...\")\n    response = ask_gemma(prompt)\n    \n    print(f\"\\nSakhi says: {response}\")\n\n# --- Example of how to use it ---\n# empathetic_talk()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-16T13:17:51.420026Z","iopub.execute_input":"2025-08-16T13:17:51.421172Z","iopub.status.idle":"2025-08-16T13:17:51.426946Z","shell.execute_reply.started":"2025-08-16T13:17:51.421127Z","shell.execute_reply":"2025-08-16T13:17:51.425779Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"# --- FEATURE 2: EMPATHETIC TALK ---\ndef empathetic_talk():\n    \"\"\"\n    Provides a safe space for the user to share their problems and get a spoken, non-judgmental response.\n    \"\"\"\n    print(\"\\n--- Feature 2: A Safe Space to Talk ---\")\n    user_problem = input(\"Sakhi is here to listen. What's on your mind today? (You can share anything) \")\n\n    prompt = f\"You are Sakhi, an AI companion for a woman in rural India. She is sharing a personal problem: '{user_problem}'. Your task is to listen, validate her feelings by saying something like 'That sounds really tough' or 'I understand', and offer gentle reassurance. Do not give advice. Just be a supportive and non-judgmental friend. Keep your response short and in simple English.\"\n\n    print(\"\\nSakhi is thinking...\")\n    response = ask_gemma(prompt)\n\n    print(f\"Sakhi says: {response}\")\n    speak(response)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-16T13:17:45.384604Z","iopub.execute_input":"2025-08-16T13:17:45.385141Z","iopub.status.idle":"2025-08-16T13:17:45.392264Z","shell.execute_reply.started":"2025-08-16T13:17:45.385100Z","shell.execute_reply":"2025-08-16T13:17:45.390882Z"}},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":"# Feature 3: Mother Health Reminders ðŸ¤°\nThis uses pre-defined data (a dictionary) to give reminders. This is your \"Edge AI calendar logic\".","metadata":{}},{"cell_type":"code","source":"# --- FEATURE 3: MATERNAL HEALTH REMINDERS ---\n# We store the reminders on the device. This is fast and works offline.\nmaternal_reminders = {\n    \"4\": \"It's early, but remember to take Folic Acid daily. It's very important for your baby's brain.\",\n    \"12\": \"Time for your first major check-up and Tetanus (TT-1) vaccine. Visit your local ASHA worker.\",\n    \"20\": \"Your baby is growing! Ensure you are eating iron-rich foods like spinach and lentils.\",\n    \"28\": \"This is the time for your second Tetanus (TT-2) shot. Don't miss it!\",\n    \"36\": \"Prepare a bag for the hospital. Keep everything ready. Rest as much as you can.\"\n}\n\ndef get_maternal_reminder():\n    \"\"\"\n    Asks for the week of pregnancy and gives a relevant, offline reminder.\n    \"\"\"\n    print(\"\\n--- Maternal Health Reminders ---\")\n    try:\n        week = input(\"Shakhi asks: How many weeks pregnant are you? (e.g., 12) \")\n        if week in maternal_reminders:\n            reminder = maternal_reminders[week]\n            print(f\"\\nShakhi's Reminder: {reminder}\")\n        else:\n            print(\"\\nShakhi says: I don't have a specific tip for that week, but remember to eat healthy and rest well.\")\n    except:\n        print(\"Sorry, please enter a number.\")\n\n# --- Example of how to use it ---\n# get_maternal_reminder()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-16T13:18:54.795423Z","iopub.execute_input":"2025-08-16T13:18:54.795890Z","iopub.status.idle":"2025-08-16T13:18:54.804091Z","shell.execute_reply.started":"2025-08-16T13:18:54.795859Z","shell.execute_reply":"2025-08-16T13:18:54.802938Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"# --- FEATURE 3: MATERNAL HEALTH REMINDERS ---\n# This data is stored ON-DEVICE. This is your \"Edge AI Calendar Logic\". It's fast and 100% offline.\nmaternal_reminders = {\n    \"4\": \"Remember to take Folic Acid every day. It is very important for your baby's brain.\",\n    \"12\": \"It is time for your first major check-up and the Tetanus (TT-1) vaccine. Please visit your local health worker.\",\n    \"20\": \"Your baby is growing fast! Eat iron-rich foods like spinach, lentils, and bananas to stay strong.\",\n    \"28\": \"Time for your second Tetanus (TT-2) vaccine. This will protect you and your baby. Don't miss it!\",\n    \"36\": \"Keep your bag ready for the hospital. Rest as much as you can. You are doing great.\"\n}\n\ndef get_maternal_reminder():\n    \"\"\"\n    Asks for the week of pregnancy and gives a relevant, spoken, offline reminder.\n    \"\"\"\n    print(\"\\n--- Feature 3: Maternal Health Reminders ---\")\n    try:\n        week = input(\"Sakhi asks: How many weeks pregnant are you? (e.g., 12) \")\n        if week in maternal_reminders:\n            reminder = maternal_reminders[week]\n            print(f\"\\nSakhi's Reminder: {reminder}\")\n            speak(reminder)\n        else:\n            response = \"I don't have a specific tip for that week, but always remember to eat healthy food and drink lots of water.\"\n            print(f\"\\nSakhi says: {response}\")\n            speak(response)\n    except:\n        print(\"Sorry, please enter a number.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-16T13:18:58.578757Z","iopub.execute_input":"2025-08-16T13:18:58.579223Z","iopub.status.idle":"2025-08-16T13:18:58.587704Z","shell.execute_reply.started":"2025-08-16T13:18:58.579191Z","shell.execute_reply":"2025-08-16T13:18:58.586342Z"}},"outputs":[],"execution_count":17},{"cell_type":"markdown","source":"# Feature 4: Health + Period TrackerðŸ©¸\nSimilar to the above, this uses simple offline logic to give wellness tips.","metadata":{}},{"cell_type":"code","source":"# --- FEATURE 4: PERIOD & WELLNESS TRACKER ---\ndef period_wellness_tip():\n    \"\"\"\n    Gives wellness tips based on the day of the menstrual cycle.\n    \"\"\"\n    print(\"\\n--- Period Wellness Tips ---\")\n    try:\n        day = int(input(\"Sakhi asks: Which day of your monthly cycle is it? (1-28) \"))\n        tip = \"\"\n        if 1 <= day <= 5:\n            tip = \"This is your period. Rest well, drink warm water, and eat iron-rich foods.\"\n        elif 6 <= day <= 13:\n            tip = \"Your energy might be returning. It's a good time for light exercise like walking.\"\n        elif 14 <= day <= 17:\n            tip = \"This is your ovulation phase. You are most fertile now.\"\n        else:\n            tip = \"In this phase, you might feel bloated or have cravings. Try to eat fruits and avoid too much salt.\"\n        \n        print(f\"\\nShakhi's Tip: {tip}\")\n    except:\n        print(\"Sorry, please enter a number between 1 and 28.\")\n\n# --- Example of how to use it ---\n# period_wellness_tip()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-16T13:19:09.963215Z","iopub.execute_input":"2025-08-16T13:19:09.964204Z","iopub.status.idle":"2025-08-16T13:19:09.972166Z","shell.execute_reply.started":"2025-08-16T13:19:09.964162Z","shell.execute_reply":"2025-08-16T13:19:09.970437Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"# --- FEATURE 4: PERIOD & WELLNESS TRACKER ---\ndef period_wellness_tip():\n    \"\"\"\n    Gives spoken wellness tips based on the day of the menstrual cycle using on-device logic.\n    \"\"\"\n    print(\"\\n--- Feature 4: Period Wellness Tips ---\")\n    try:\n        day = int(input(\"Sakhi asks: To get a wellness tip, please enter the day of your monthly cycle (1-28): \"))\n        tip = \"\"\n        if 1 <= day <= 5:\n            tip = \"This is your period. It is okay to rest. Drink warm water and eat greens to feel better.\"\n        elif 6 <= day <= 13:\n            tip = \"Your energy is likely returning. This is a great time for a nice walk or light exercise.\"\n        elif 14 <= day <= 17:\n            tip = \"This is your ovulation phase. Your body is strongest now. Listen to what it needs.\"\n        else:\n            tip = \"You might feel a bit tired or crave certain foods. Eating fruits can help. Be kind to yourself.\"\n\n        print(f\"\\nSakhi's Tip: {tip}\")\n        speak(tip)\n    except:\n        print(\"Sorry, that's not a valid day. Please enter a number from 1 to 28.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-16T13:19:40.388534Z","iopub.execute_input":"2025-08-16T13:19:40.388959Z","iopub.status.idle":"2025-08-16T13:19:40.396355Z","shell.execute_reply.started":"2025-08-16T13:19:40.388931Z","shell.execute_reply":"2025-08-16T13:19:40.395202Z"}},"outputs":[],"execution_count":20},{"cell_type":"markdown","source":"# Feature 5: English + Local Language Toggle ðŸŒ\nThis simulates translation using Gemma. For a real app, you'd use a dedicated offline translation model, but this is a fantastic way to demo the capability.","metadata":{}},{"cell_type":"code","source":"# --- FEATURE 5: LANGUAGE TOGGLE (SIMULATION) ---\ndef translate_to_hindi(text):\n    \"\"\"\n    Uses Gemma to translate a given text from English to Hindi.\n    \"\"\"\n    print(\"\\nTranslating to Hindi...\")\n    # This prompt technique is called \"zero-shot prompting\"\n    prompt = f\"Translate the following English sentence into simple, conversational Hindi: '{text}'\"\n    \n    hindi_translation = ask_gemma(prompt)\n    print(f\"Hindi: {hindi_translation}\")\n\n# --- Example of how to use it ---\n# english_text = maternal_reminders[\"12\"]\n# print(f\"Original English: {english_text}\")\n# translate_to_hindi(english_text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-16T13:20:05.146721Z","iopub.execute_input":"2025-08-16T13:20:05.147212Z","iopub.status.idle":"2025-08-16T13:20:05.154050Z","shell.execute_reply.started":"2025-08-16T13:20:05.147176Z","shell.execute_reply":"2025-08-16T13:20:05.152781Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"# --- FEATURE 5: LANGUAGE TOGGLE (HINDI DEMO) ---\ndef translate_to_hindi(text):\n    \"\"\"\n    Uses Gemma to translate a given text from English to Hindi to demonstrate the bilingual capability.\n    \"\"\"\n    print(\"\\n--- Feature 5: Language Toggle Demo ---\")\n    print(f\"\\nOriginal English Text: '{text}'\")\n    print(\"\\nSakhi is translating to Hindi...\")\n\n    # We use a technique called \"zero-shot prompting\" to make the AI a translator.\n    prompt = f\"Translate the following simple English sentence into conversational Hindi: '{text}'\"\n\n    hindi_translation = ask_gemma(prompt)\n    print(f\"Sakhi's Hindi Translation: {hindi_translation}\")\n    speak(hindi_translation, lang='hi')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-16T13:20:19.057270Z","iopub.execute_input":"2025-08-16T13:20:19.057723Z","iopub.status.idle":"2025-08-16T13:20:19.064462Z","shell.execute_reply.started":"2025-08-16T13:20:19.057693Z","shell.execute_reply":"2025-08-16T13:20:19.063204Z"}},"outputs":[],"execution_count":23},{"cell_type":"markdown","source":"# Step 4: The Final App - Putting It All Together\nNow, let's create a simple interactive menu so the judges can easily test all the features. This loop will run until the user decides to quit.\n\n## ðŸ§  Shakhi AI â€” The Final Presentation-Ready Demo ðŸ†","metadata":{}},{"cell_type":"code","source":"# ===================================================================\n# FINAL HACKATHON SUBMISSION: SAKHI AI\n# By: Amit\n# This is the complete, error-free code for the interactive demo.\n# ===================================================================\n\n# --- PART 1: SETUP & LIBRARIES ---\n# This section ensures all necessary tools are ready.\nprint(\"STEP 1 of 3: Preparing Sakhi's environment...\")\n# We use '%%capture' to hide the installation output for a cleaner demo screen.\nget_ipython().run_cell_magic('capture', '', '!pip install -q -U transformers accelerate bitsandbytes sentence-transformers gtts\\n')\n\nimport torch\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\nfrom kaggle_secrets import UserSecretsClient\nfrom huggingface_hub import login\nfrom gtts import gTTS\nfrom IPython.display import Audio, display, clear_output\nimport time\n\nprint(\"âœ… Environment is ready!\")\ntime.sleep(1) # Added a small pause for dramatic effect in the presentation\n\n# ===================================================================\n# --- PART 2: LOAD THE AI BRAIN (GEMMA) ---\n# ===================================================================\nprint(\"\\nSTEP 2 of 3: Loading Sakhi's AI Brain (Gemma)...\")\nprint(\"This may take a few minutes. Please ignore any 'factory' warnings.\")\n\n# --- Login to Hugging Face to get model access ---\ntry:\n    user_secrets = UserSecretsClient()\n    hf_token = user_secrets.get_secret(\"HF_TOKEN\")\n    login(token=hf_token)\n    print(\"âœ… Securely logged into Hugging Face.\")\nexcept Exception as e:\n    print(\"âš ï¸ Could not log in. Please ensure HF_TOKEN is in Kaggle Secrets.\")\ntime.sleep(1)\n\n# --- Configure and load the Gemma model ---\nmodel_id = \"google/gemma-2b-it\"\nquantization_config = BitsAndBytesConfig(load_in_8bit=True)\n\ntokenizer = AutoTokenizer.from_pretrained(model_id)\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_id,\n    quantization_config=quantization_config,\n    device_map=\"auto\"\n)\n\nprint(\"\\nâœ… Sakhi's AI Brain is now online and running offline!\")\ntime.sleep(2) # Pause before starting the demo\n\n# ===================================================================\n# --- PART 3: THE SAKHI AI INTERACTIVE DEMO ---\n# ===================================================================\n\n# --- Helper functions for AI chat and voice output ---\ndef ask_gemma(prompt_text):\n    \"\"\"Sends a prompt to the AI and gets a clean response.\"\"\"\n    input_ids = tokenizer(prompt_text, return_tensors=\"pt\").to(\"cuda\")\n    outputs = model.generate(**input_ids, max_new_tokens=150)\n    response_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n    return response_text.replace(prompt_text, \"\").strip()\n\ndef speak(text, lang='en'):\n    \"\"\"Simulates Sakhi speaking the text.\"\"\"\n    print(f\"\\nSakhi says: {text}\")\n    try:\n        tts = gTTS(text=text, lang=lang, slow=False)\n        tts.save(\"sakhi_speaks.mp3\")\n        display(Audio(\"sakhi_speaks.mp3\", autoplay=True))\n    except Exception as e:\n        print(f\"(Could not play audio due to: {e})\")\n\n# --- The 5 Core Features, defined as functions ---\ndef feature_mood_checkin():\n    clear_output(wait=True); print_header(\"Feature 1: Daily Mood Check-in â˜€ï¸\")\n    user_mood = input(\"Sakhi asks: In one word, how are you feeling today?\\n> \")\n    prompt = f\"You are Sakhi, a kind friend. A user says she is feeling '{user_mood}'. Respond with a short, warm, and encouraging message in simple English. Do not ask a question.\"\n    print(\"\\nSakhi is thinking...\")\n    response = ask_gemma(prompt); speak(response)\n    input(\"\\nPress Enter to return to the menu...\")\n\ndef feature_empathetic_talk():\n    clear_output(wait=True); print_header(\"Feature 2: A Safe Space to Talk ðŸ’¬\")\n    user_problem = input(\"Sakhi is here to listen. What's on your mind?\\n> \")\n    prompt = f\"You are Sakhi, an AI friend for a rural woman. She says: '{user_problem}'. Validate her feelings by saying something like 'That sounds really tough', and offer gentle reassurance. Do not give advice. Be a supportive friend.\"\n    print(\"\\nSakhi is thinking...\"); response = ask_gemma(prompt); speak(response)\n    input(\"\\nPress Enter to return to the menu...\")\n\nmaternal_reminders = {\n    \"12\": \"It's time for your first check-up and the Tetanus (TT-1) vaccine. Please see your local health worker.\",\n    \"20\": \"Your baby is growing! Eat iron-rich foods like spinach and lentils to stay strong.\",\n    \"28\": \"Time for your second Tetanus (TT-2) shot. This protects you and your baby.\"\n}\ndef feature_maternal_reminders():\n    clear_output(wait=True); print_header(\"Feature 3: Maternal Health Reminders ðŸ¤°\")\n    week = input(\"Sakhi asks: How many weeks pregnant are you? (e.g., 12, 20, 28)\\n> \")\n    reminder = maternal_reminders.get(week, \"Remember to always eat healthy food and drink lots of water.\")\n    speak(reminder)\n    input(\"\\nPress Enter to return to the menu...\")\n\ndef feature_period_tracker():\n    clear_output(wait=True); print_header(\"Feature 4: Period & Wellness Tracker ðŸ©¸\")\n    try:\n        day = int(input(\"Sakhi asks: Which day of your monthly cycle is it? (1-28)\\n> \"))\n        tip = \"Remember to be kind to yourself today.\"\n        if 1 <= day <= 5: tip = \"This is your period. It is okay to rest. Drink warm water to feel better.\"\n        elif 6 <= day <= 13: tip = \"Your energy is likely returning. This is a great time for a nice walk.\"\n        speak(tip)\n    except:\n        speak(\"Sorry, please enter a valid number.\")\n    input(\"\\nPress Enter to return to the menu...\")\n\ndef feature_language_toggle():\n    clear_output(wait=True); print_header(\"Feature 5: Hindi Language Toggle ðŸŒ\")\n    text_to_translate = maternal_reminders[\"20\"]\n    print(f\"English Text: '{text_to_translate}'\")\n    prompt = f\"Translate the following simple English sentence into conversational Hindi: '{text_to_translate}'\"\n    print(\"\\nSakhi is translating...\")\n    hindi_translation = ask_gemma(prompt)\n    speak(hindi_translation, lang='hi')\n    input(\"\\nPress Enter to return to the menu...\")\n\ndef print_header(title):\n    print(\"=\"*50); print(f\"ðŸŒ¸ SAKHI AI DEMO: {title}\"); print(\"=\"*50)\n\n# --- The Main Application Loop ---\ndef main_demo():\n    while True:\n        clear_output(wait=True)\n        # The multi-line print statement is now fixed with triple quotes \"\"\"\n        print(\"\"\"\n          â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•—  â–ˆâ–ˆâ•—â–ˆâ–ˆâ•— â–ˆâ–ˆâ•—\n          â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘ â–ˆâ–ˆâ•‘\n          â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘ â–ˆâ–ˆâ•‘\n          â•šâ•â•â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•‘â•šâ•â• â•šâ•â•\n          â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•— â–ˆâ–ˆâ•—\n          â•šâ•â•â•â•â•â•â•â•šâ•â•  â•šâ•â•â•šâ•â•  â•šâ•â•â•šâ•â• â•šâ•â•\n        Your Private AI Friend for Health & Wellness\n        \"\"\")\n        print(\"=\"*50); print(\" JUDGES' MENU - SELECT A FEATURE TO TEST\"); print(\"=\"*50)\n        print(\"1. Daily Mood Check-in (Emotional AI)\")\n        print(\"2. Safe, Empathetic Talk (Conversational AI)\")\n        print(\"3. Maternal Health Reminders (Offline Health Logic)\")\n        print(\"4. Period & Wellness Tips (On-Device AI)\")\n        print(\"5. English to Hindi Translation (Accessibility)\")\n        print(\"\\n6. Exit Demo\")\n\n        choice = input(\"\\nEnter your choice [1-6]: \")\n        if choice == '1': feature_mood_checkin()\n        elif choice == '2': feature_empathetic_talk()\n        elif choice == '3': feature_maternal_reminders()\n        elif choice == '4': feature_period_tracker()\n        elif choice == '5': feature_language_toggle()\n        elif choice == '6':\n            clear_output(wait=True)\n            print(\"\\nThank you for using Sakhi AI. â¤ï¸\")\n            speak(\"Thank you for talking with me. Take care!\")\n            break\n\n# --- INITIATE THE DEMO ---\nmain_demo()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-16T19:31:29.105397Z","iopub.execute_input":"2025-08-16T19:31:29.105782Z"}},"outputs":[{"name":"stdout","text":"\n          â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•—  â–ˆâ–ˆâ•—â–ˆâ–ˆâ•— â–ˆâ–ˆâ•—\n          â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘ â–ˆâ–ˆâ•‘\n          â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘ â–ˆâ–ˆâ•‘\n          â•šâ•â•â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•‘â•šâ•â• â•šâ•â•\n          â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•— â–ˆâ–ˆâ•—\n          â•šâ•â•â•â•â•â•â•â•šâ•â•  â•šâ•â•â•šâ•â•  â•šâ•â•â•šâ•â• â•šâ•â•\n        Your Private AI Friend for Health & Wellness\n        \n==================================================\n JUDGES' MENU - SELECT A FEATURE TO TEST\n==================================================\n1. Daily Mood Check-in (Emotional AI)\n2. Safe, Empathetic Talk (Conversational AI)\n3. Maternal Health Reminders (Offline Health Logic)\n4. Period & Wellness Tips (On-Device AI)\n5. English to Hindi Translation (Accessibility)\n\n6. Exit Demo\n","output_type":"stream"}],"execution_count":null},{"cell_type":"markdown","source":"# Why Sakhi AI Matters\n\nAI should empower the underserved, not just the elite\n\nSakhi AI respects privacy, language, culture\n\nIt's small, useful, private, and warm\n\nJudges: This is India's First ChatGPT for rural women","metadata":{}},{"cell_type":"markdown","source":"# T H A N K    Y O U","metadata":{}}]}